{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtKllKL-EFgx"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Project 1a: Intro to PyTorch Mini-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3962,
     "status": "ok",
     "timestamp": 1611952535610,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "82H_i6foD8A_",
    "outputId": "3d13ba10-8e5f-4027-c706-bbb746229a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Found GPU')\n",
    "else:\n",
    "    print('Did not find GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlDcpSk3VW5l"
   },
   "source": [
    "### Part-of-Speech Tagging\n",
    "\n",
    "You'll be trying to predict the most common [part of speech](https://web.stanford.edu/~jurafsky/slp3/8.pdf) for a word from its characters.  This project will focus on word types rather than tokens and not use any context (https://en.wikipedia.org/wiki/Type%E2%80%93token_distinction). This task is different from (and simpler than) a standard part-of-speech tagging task, which predicts part-of-speech tags for tokens in their sentential context.\n",
    "\n",
    "Many words can have multiple different parts of speech, but in this project we will associate each word only with its most common part of speech in the [Brown Corpus](https://www1.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html), which has been manually labeled with part-of-speech tags.  \n",
    "\n",
    "Words are lowercased and filtered for length and frequency. Punctuation and numbers are removed. Any real NLP application would have to deal with the actual contents of text instead of filtering in this way, but we're just warming up.\n",
    "\n",
    "Below, we provide you with code to load the dataset. Please don't change the cell below, or you may confuse our autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7714,
     "status": "ok",
     "timestamp": 1611952543776,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "9T1ijH6-WlSp",
    "outputId": "016bdecd-b637-4b42-c95d-25b73c6cc456"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\zzxf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\zzxf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged tokens example:  [('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN')]\n",
      "Total # of word tokens: 1161192\n",
      "Tagged types example:  [('a', 'DET'), ('aaron', 'NOUN'), ('ab', 'NOUN'), ('abandon', 'VERB'), ('abandoned', 'VERB')]\n",
      "Total # of word types: 18954\n",
      "Tag options: ['ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "brown_tokens = brown.tagged_words(tagset='universal')\n",
    "print('Tagged tokens example: ', brown_tokens[:5])\n",
    "print('Total # of word tokens:', len(brown_tokens))\n",
    "\n",
    "max_word_len = 20\n",
    "\n",
    "def most_common(s):\n",
    "    \"Return the most common element in a sequence.\"\n",
    "    return Counter(s).most_common(1)[0][0]\n",
    "\n",
    "def most_common_tags(tagged_words, min_count=3, max_len=max_word_len):\n",
    "    \"Return a dictionary of the most common tag for each word, filtering a bit.\"\n",
    "    counts = defaultdict(list)\n",
    "    for w, t in tagged_words:\n",
    "        counts[w.lower()].append(t)\n",
    "    return {w: most_common(tags) for w, tags in counts.items() if \n",
    "            w.isalpha() and len(w) <= max_len and len(tags) >= min_count}\n",
    "\n",
    "brown_types = most_common_tags(brown_tokens)\n",
    "print('Tagged types example: ', sorted(brown_types.items())[:5])\n",
    "print('Total # of word types:', len(brown_types))\n",
    "\n",
    "def split(items, test_size):\n",
    "    \"Randomly split into train, validation, and test sets with a fixed seed.\"\n",
    "    random.Random(288).shuffle(items)\n",
    "    once, twice = test_size, 2 * test_size\n",
    "    return items[:-twice], items[-twice:-once], items[-once:]\n",
    "\n",
    "val_test_size = 1000\n",
    "all_data_raw = split(sorted(brown_types.items()), val_test_size)\n",
    "train_data_raw, validation_data_raw, test_data_raw = all_data_raw\n",
    "all_tags = sorted(set(brown_types.values()))\n",
    "print('Tag options:', all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIx-VMZT7zSn"
   },
   "source": [
    "You're welcome to insert additional cells and explore the data. Our autograders don't rely on any particular structure of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XVJkfwD37w1G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_raw: 16954\n",
      "validation_data_raw: 1000\n",
      "test_data_raw: 1000\n",
      "list中的元素类型: <class 'tuple'>\n",
      "Tag options: ['ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
      "数据集是以list的形式保存的，list中保存着元组，元组是单词与词性label的一一对应\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data_raw:\",len(train_data_raw))\n",
    "print(\"validation_data_raw:\",len(validation_data_raw))\n",
    "print(\"test_data_raw:\",len(test_data_raw))\n",
    "print(\"list中的元素类型:\",type(train_data_raw[0]))\n",
    "print('Tag options:', all_tags)\n",
    "print(\"数据集是以list的形式保存的，list中保存着元组，元组是单词与词性label的一一对应\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiZ4q4aqVRVF"
   },
   "source": [
    "First, let's run a baseline that predicts `NOUN` for every word. A predictor function takes a list of tagged words and returns a list of predicted tags. We've also provided some helper functions here to evaluate model outputs.  You don't need to fill in any code in this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1611952553077,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "FvoPZ609WBpN",
    "outputId": "06a6a6d5-a459-4dbd-d224-52b1bc02c573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun baseline validation accuracy: 55.1\n",
      "Sample predictions: [('salem', 'NOUN'), ('unsympathetic', 'NOUN'), ('downwind', 'NOUN'), ('exodus', 'NOUN'), ('avoiding', 'NOUN'), ('informal', 'NOUN'), ('padded', 'NOUN'), ('tantalizing', 'NOUN'), ('farce', 'NOUN'), ('berger', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "def noun_predictor(raw_data):\n",
    "    \"A predictor that always predicts NOUN.\"\n",
    "    predictions = []\n",
    "    for word, _ in raw_data:\n",
    "        predictions.append('NOUN')\n",
    "    return predictions\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"Return the accuracy percentage of a list of predictions.\n",
    "    \n",
    "    predictions has only the predicted tags\n",
    "    targets has tuples of (word, tag)\n",
    "    \"\"\"\n",
    "    assert len(predictions) == len(targets)\n",
    "    n_correct = 0\n",
    "    # YOUR CODE HERE\n",
    "    # * count the number of matches between predictions and targets\n",
    "    \n",
    "    for predicted_tag, (word, gold_tag) in zip(predictions, targets):\n",
    "        if predicted_tag == gold_tag:\n",
    "            n_correct += 1\n",
    "    return n_correct / len(targets) * 100.0\n",
    "    \n",
    "\n",
    "def evaluate(predictor, raw_data):\n",
    "    return accuracy(predictor(raw_data), raw_data)\n",
    "\n",
    "def print_sample_predictions(predictor, raw_data, k=10):\n",
    "    \"Print the first k predictions.\"\n",
    "    d = raw_data[:k]\n",
    "    print('Sample predictions:', \n",
    "          [(word, guess) for (word, _), guess in zip(d, predictor(d))])\n",
    "\n",
    "print('noun baseline validation accuracy:', \n",
    "      evaluate(noun_predictor, validation_data_raw))\n",
    "print_sample_predictions(noun_predictor, validation_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIxSaG7pavpS"
   },
   "source": [
    "### Building a PyTorch Classifier\n",
    "\n",
    "We will be using the deep learning framework PyTorch for all our projects.\n",
    "If you haven't used PyTorch at all before, we recommend you check out the tutorials on the PyTorch website: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html.  Throughout this project and the others in this course, you will need to reference the documentation at https://pytorch.org/docs/stable/index.html.  We'll be using PyTorch version 1.7, which comes pre-installed with Colab.  In this project, we'll walk you through the process of defining and training your neural network model, but future projects will have less guidance.\n",
    "\n",
    "Below, we've provided a baseline network as a PyTorch Module that will learn a single parameter per part-of-speech tag. This model has the capacity to learn that `'NOUN'` is the most common tag and predict that. It can't do better. Use this network as you are developing your training and prediction code, then replace it with your actual network later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3N8wiRpoiZzG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineNetwork(nn.Module):\n",
    "    def __init__(self, n_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        # learn a vector of size n_outputs, initialized with all zeros\n",
    "        self.param = nn.Parameter(torch.zeros(n_outputs)) \n",
    "\n",
    "    def forward(self, chars, mask):\n",
    "        # return the same outputs (self.param) for each example in a batch\n",
    "        return self.param.expand(chars.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnJJfdiR8l_L"
   },
   "source": [
    "To train or evaluate a neural model, we'll need to transform the raw data from strings into tensors.  We've provided the following function to perform the transformation for you. Each word is prepended with the `^` character and appended with `$` so that these boundary characters are available to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1611952578879,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "f62L4sTrUEn3",
    "outputId": "368baefb-b4f9-4d01-b35a-7aa97be9117d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample datapoint after preprocessing: (tensor([ 94, 115,  97, 108, 101, 109,  36,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0]), tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]), tensor(5))\n",
      "Raw datapoint: ('salem', 'NOUN')\n"
     ]
    }
   ],
   "source": [
    "def make_matrices(data_raw):\n",
    "    \"\"\"Convert a list of (word, tag) pairs into tensors with appropriate padding.\n",
    "    \n",
    "    character_matrix holds character codes for each word, \n",
    "      indexed as [word_index, character_index]\n",
    "    character_mask masks valid characters (1 for valid, 0 invalid), \n",
    "      indexed similarly so that all inputs can have a constant length\n",
    "    pos_labels holds part-of-speech one-hot vectors,\n",
    "      indexed as [word_index, pos_index] with 0/1 values TODO this is wrong, pos_labels is a vector\n",
    "    \"\"\"\n",
    "    max_len = max_word_len + 2  # leave room for word start/end symbols\n",
    "    character_matrix = torch.zeros(len(data_raw), max_len, dtype=torch.int64) \n",
    "    character_mask = torch.zeros(len(data_raw), max_len, dtype=torch.float32)\n",
    "    pos_labels = torch.zeros(len(data_raw), dtype=torch.int64)\n",
    "    for word_i, (word, pos) in enumerate(data_raw):\n",
    "        for char_i, c in enumerate('^' + word + '$'):\n",
    "            character_matrix[word_i, char_i] = ord(c)\n",
    "            character_mask[word_i, char_i] = 1\n",
    "        pos_labels[word_i] = all_tags.index(pos)\n",
    "    return torch.utils.data.TensorDataset(character_matrix, character_mask, pos_labels)\n",
    "\n",
    "validation_data = make_matrices(validation_data_raw)\n",
    "\n",
    "print('Sample datapoint after preprocessing:', validation_data[0])\n",
    "print('Raw datapoint:', validation_data_raw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK-FPqtw826J"
   },
   "source": [
    "The output of a `BaselineNetwork` is a matrix of dimension (batch_size, num_pos_labels) containing logits, or unnormalized log probabilities. To get probabilities from this matrix, you would run `F.softmax(x, dim=1)`, which exponentiates the logits and then normalizes each row to sum to 1.  The cell below generates an output distribution for the first example of the validation set, which is uniform because the network param was initialized to zero.\n",
    "\n",
    "In PyTorch, it is common to return pre-activation values from modules (e.g. the values before running the final softmax or sigmoid operation).  PyTorch has loss functions that combine the softmax/sigmoid operation into the loss operation for more numerical stability.  Be sure you know what type of values a network returns, as this will affect your training and prediction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10669,
     "status": "ok",
     "timestamp": 1611952805688,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "Rtr9xZXVB1Qc",
    "outputId": "d117ebe5-84d5-41a6-c315-73a1b6095502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADJ', 0.09090909361839294),\n",
       " ('ADP', 0.09090909361839294),\n",
       " ('ADV', 0.09090909361839294),\n",
       " ('CONJ', 0.09090909361839294),\n",
       " ('DET', 0.09090909361839294),\n",
       " ('NOUN', 0.09090909361839294),\n",
       " ('NUM', 0.09090909361839294),\n",
       " ('PRON', 0.09090909361839294),\n",
       " ('PRT', 0.09090909361839294),\n",
       " ('VERB', 0.09090909361839294),\n",
       " ('X', 0.09090909361839294)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a network and copy its parameters to the GPU.\n",
    "untrained_baseline = BaselineNetwork(len(all_tags)).cuda()\n",
    "untrained_baseline.eval()\n",
    "\n",
    "# Select the first validation example.\n",
    "example = validation_data[0]\n",
    "chars, mask, _ = example\n",
    "\n",
    "# Networks only process batches. Create a batch of size one.\n",
    "chars_batch, mask_batch = chars.unsqueeze(0), mask.unsqueeze(0)\n",
    "\n",
    "# Copy batch to the GPU.\n",
    "chars_batch, mask_batch = chars_batch.cuda(), mask_batch.cuda()\n",
    "\n",
    "# Run the untrained network.\n",
    "logits = untrained_baseline(chars_batch, mask_batch)\n",
    "\n",
    "# Convert to a distribution.\n",
    "output_distribution = F.softmax(logits, dim=1).squeeze().tolist()\n",
    "\n",
    "# Inspect the distribution, which should be uniform.\n",
    "list(zip(all_tags, output_distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ubdajTtCwzt"
   },
   "source": [
    "Finally, time to write some code!\n",
    "\n",
    "In the cell below, define a predictor for a network by following the instructions in the comments. The predictor takes a list of words (strings) and returns a list of part-of-speech tags (also strings).\n",
    "\n",
    "For this assignment, we've provided more fine-grained instructions as comments in the code template.  You are free to explore methods and architectures other than the ones we specified in the comments, but we highly recommend starting with them, as they will help you reach the required accuracies and give lots of best practices to use in later projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1611952968391,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "zlWQk-dcp9BD",
    "outputId": "9636c683-d4a0-4f81-c161-8f2f7386ed8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: [('salem', 'ADJ'), ('unsympathetic', 'ADJ'), ('downwind', 'ADJ'), ('exodus', 'ADJ'), ('avoiding', 'ADJ'), ('informal', 'ADJ'), ('padded', 'ADJ'), ('tantalizing', 'ADJ'), ('farce', 'ADJ'), ('berger', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "def predict_using(network):\n",
    "    def predictor(raw_data):\n",
    "        \"\"\"Return a list of part-of-speech tags as strings, one for each word.\n",
    "\n",
    "        raw_data - a list of (word, tag) pairs.\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad(): # turns off automatic differentiation, which isn't required but helps save memory\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # * put `network` into evaluation mode (turning off dropout) using `.eval()`\n",
    "            #   then back into train mode at the end of the function with `.train()`\n",
    "            #   this is easy to forget and could lead to lower accuracy without warning\n",
    "            #   see https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train for more info\n",
    "            # * use `make_matrices` to get a preprocessed dataset from `raw_data`\n",
    "            # * make a DataLoader to iterate over the preprocessed dataset from `make_matrices`, but don't use shuffling or your outputs will be in the wrong order\n",
    "            # * iterate with the data loader (there will be a pos_labels vector, but don't use it - we want to be able to use our model on new inputs where we don't know the answer)\n",
    "            #  * run `network` to get outputs\n",
    "            #  * get the id of the predicted part of speeches with an argmax operation\n",
    "            #  * convert the predictions to strings using `all_tags`\n",
    "            # * return your predictions\n",
    "            network.eval()\n",
    "            test_data = make_matrices(raw_data)\n",
    "            dataloader = torch.utils.data.DataLoader(test_data, batch_size=128)\n",
    "            predictions = []\n",
    "            for character_matrix, character_mask, pos_labels in dataloader:\n",
    "              character_matrix = character_matrix.cuda()\n",
    "              character_mask = character_mask.cuda()\n",
    "              pos_labels = pos_labels.cuda()\n",
    "              predictions.append(\n",
    "                  torch.max(network(character_matrix, character_mask), dim=-1)[1]\n",
    "              )\n",
    "            predictions = torch.cat(predictions).cpu().numpy()\n",
    "            predictions = [all_tags[i] for i in predictions]\n",
    "            network.train()\n",
    "            return predictions\n",
    "\n",
    "\n",
    "    \n",
    "    return predictor\n",
    "\n",
    "# The predictions of an untrained model should be arbitrary.\n",
    "print_sample_predictions(predict_using(untrained_baseline), validation_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_9jzlbFB1hw"
   },
   "source": [
    "\n",
    "Fill in the training function for the neural network below. This function should train any network.  \n",
    "\n",
    "Then, you'll have all the parts needed to train and evaluate the baseline network.  You should get the same accuracy as the all-noun baseline.  Make sure your train function prints validation scores so that you see score outputs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3909,
     "status": "ok",
     "timestamp": 1611952988615,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "w7ce8kZd-5pj",
    "outputId": "dadafa1e-5d8c-4287-cfe8-d6cc8003db67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzxf\\AppData\\Local\\Temp\\ipykernel_6592\\2165647061.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm.tqdm_notebook(data_loader, leave=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 55.1\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 55.1\n",
      "Sample predictions: [('salem', 'NOUN'), ('unsympathetic', 'NOUN'), ('downwind', 'NOUN'), ('exodus', 'NOUN'), ('avoiding', 'NOUN'), ('informal', 'NOUN'), ('padded', 'NOUN'), ('tantalizing', 'NOUN'), ('farce', 'NOUN'), ('berger', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def train(network, n_epochs=25):\n",
    "    # YOUR CODE HERE\n",
    "    # * use `make_matrices` to get a preprocessed dataset from `train_data_raw`\n",
    "    # * make a DataLoader from torch.utils.data to iterate over your dataset\n",
    "    #   it can handle batching and shuffling of the data, you just need to pass it the `batch_size` and `shuffle` parameters\n",
    "    # * move `network` to GPU using `.cuda()`\n",
    "    # * make an optimizer from torch.optim with your network parameters\n",
    "    #   `Adam` with its default hyperparameters often works pretty well without any tuning\n",
    "    #   later you can explore other optimizers, as well as learning rate schedules\n",
    "    device = torch.device(\"cuda:0\" )\n",
    "    network=network.to(device)\n",
    "    train_data = make_matrices(train_data_raw)\n",
    "    data_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    \n",
    "    network.train()\n",
    "    predictor = predict_using(network)\n",
    "    optimizer=torch.optim.Adam(network.parameters())\n",
    "    criterion=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    best_score=0\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch', epoch)\n",
    "        for batch in tqdm.tqdm_notebook(data_loader, leave=False):\n",
    "            chars_batch, mask_batch, pos_batch = batch\n",
    "            \n",
    "            assert network.training, 'make sure your network is in train mode with `.train()`'\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # * call zero_grad on your optimizer\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            #   warning: this is easy to forget and you won't get an error if you do - you might just get lower accuracies\n",
    "            # * move the batch inputs to GPU\n",
    "            chars_batch=chars_batch.to(device)\n",
    "            mask_batch=mask_batch.to(device)\n",
    "            pos_batch=pos_batch.to(device)\n",
    "            \n",
    "            # * run your network\n",
    "            outputs = network(chars_batch, mask_batch)\n",
    "            loss = criterion(outputs, pos_batch)\n",
    "            # * compute a loss; you can use `F.cross_entropy`, which combines a softmax operation with\n",
    "            #   a cross-entropy loss operation for multi-class classification\n",
    "            # * call `.backward()` on your loss and `.step()` on your optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        #print(predictor)\n",
    "        validation_score = evaluate(predictor, validation_data_raw)\n",
    "        print('Validation score:', validation_score)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # * if the validation score is better than your previous best score, save the model\n",
    "        if validation_score > best_score:\n",
    "            best_score=validation_score\n",
    "            torch.save(network.state_dict(), './best.pt')\n",
    "        #   use `network.state_dict()` and `torch.save` (https://pytorch.org/docs/stable/notes/serialization.html)\n",
    "        #   this gives us a form of early stopping in case the model starts overfitting\n",
    "\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # * load the best model from the file where you saved it using `torch.load` and `network.load_state_dict`\n",
    "    #   and return it\n",
    "    network.load_state_dict(torch.load('./best.pt'))\n",
    "    return network\n",
    "\n",
    "\n",
    "\n",
    "trained_baseline_network = train(BaselineNetwork(len(all_tags)), 2)\n",
    "print_sample_predictions(predict_using(trained_baseline_network), validation_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfDfOpTj41mj"
   },
   "source": [
    "It's time to actually define a non-trivial neural network.  We'll start with a pretty simple model that takes embeddings of the characters of a word, pools them, and runs a feedforward network.  Fill in your code for `PoolingNetwork` below.  A correct implementation should get a validation score over 66%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 36487,
     "status": "ok",
     "timestamp": 1611953054602,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "nbJgzzO8SOJ_",
    "outputId": "8091d835-bcb1-4a1c-ad30-5f0914064238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzxf\\AppData\\Local\\Temp\\ipykernel_6592\\2165647061.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm.tqdm_notebook(data_loader, leave=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 55.800000000000004\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 59.699999999999996\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 60.8\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 60.9\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 61.7\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 61.6\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 62.7\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 62.8\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 63.5\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 64.1\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 64.5\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 64.9\n",
      "Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 65.0\n",
      "Epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 65.10000000000001\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 65.5\n",
      "Epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 65.8\n",
      "Epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.10000000000001\n",
      "Epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.10000000000001\n",
      "Epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.2\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.10000000000001\n",
      "Epoch 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.3\n",
      "Epoch 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.3\n",
      "Epoch 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.5\n",
      "Epoch 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.3\n",
      "Epoch 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a23ac7db73b43548e0db840fcd60dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 66.4\n"
     ]
    }
   ],
   "source": [
    "class PoolingNetwork(nn.Module):\n",
    "    def __init__(self, n_outputs): # pass whatever arguments you need\n",
    "        super().__init__() # you will get an error if you don't call the parent class __init__\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # create Modules from torch.nn (imported as nn)\n",
    "        # here you will need nn.Embedding and two nn.Linear\n",
    "        # you may find it easier to start with the `forward` method and as you need components come back to place them here\n",
    "        self.embed=nn.Embedding(128,64)\n",
    "        self.fc1=nn.Linear(64,128)\n",
    "        self.fc2=nn.Linear(128,n_outputs)\n",
    "        self.dropout=nn.Dropout()\n",
    "        self.relu= torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, chars, mask): # the main method that runs this module\n",
    "        # for this network, `chars` should be an int64 tensor of character ids with size (batch, n_chars)\n",
    "        #   note that sometimes PyTorch puts sequence dimensions before the batch, so you will need to make sure you know which you are using\n",
    "        # `mask` is a float32 tensor of size (batch, n_chars) that is 1.0 if the character at that position in `chars` is valid (else 0.0)\n",
    "        # the function returns a float32 tensor of size (batch, n_pos)\n",
    "        \n",
    "        # we recommend that you return pre-activation values from modules (e.g. the values before running softmax or sigmoid)\n",
    "        # pytorch has loss functions that combine the softmax/sigmoid operation into the loss operation for more numerical stability\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Your code should do the following:\n",
    "        # 1) get character embeddings\n",
    "        # 2) multiply embeddings by `mask` (you will need to use `view` or `unsqueeze` to make the broadcasting work correctly;\n",
    "        #    see https://pytorch.org/docs/stable/notes/broadcasting.html)\n",
    "        # 3) pool over the characters of each word with the Tensor `mean` function\n",
    "        # 4) run a linear layer\n",
    "        # 5) apply an activation (ReLU is a decent default choice; look in torch.nn.functional, which is imported as F)\n",
    "        # 6) run dropout; you can either make a nn.Dropout module in __init__ or use F.dropout, but if you use F.dropout, be sure to pass training=self.training to\n",
    "        #    make sure dropout gets turned off during evaluation\n",
    "        # 7) run your second linear layer and return the output\n",
    "        pooled = torch.mean(\n",
    "            self.embed(chars) * torch.unsqueeze(mask, -1),\n",
    "            dim=1\n",
    "        )\n",
    "        output=self.fc1(pooled)\n",
    "        output=self.relu(output)\n",
    "        output=self.dropout(output)\n",
    "        output=self.fc2(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "trained_pooling_network = train(PoolingNetwork(len(all_tags)))\n",
    "pooling_predictor = predict_using(trained_pooling_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9iRzg47SUbD"
   },
   "source": [
    "And look at some outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 86348,
     "status": "ok",
     "timestamp": 1611628997794,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "fv00vHSlSSbe",
    "outputId": "cd1ea11e-c4a5-47b1-f0fb-7ee33596c2eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: [('salem', 'NOUN'), ('unsympathetic', 'NOUN'), ('downwind', 'NOUN'), ('exodus', 'VERB'), ('avoiding', 'VERB'), ('informal', 'NOUN'), ('padded', 'VERB'), ('tantalizing', 'VERB'), ('farce', 'NOUN'), ('berger', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "print_sample_predictions(pooling_predictor, validation_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-NnQ1Q4q-6U"
   },
   "source": [
    "For this next part, we'll give you a little more freedom to experiment.  Think about what types of information could be useful for predicting parts of speech.  Think about what the pooling model is missing.  Implement an improved model that reaches a validation score above 75%.\n",
    "\n",
    "One way to reach the required accuracy is to operate over character n-grams before pooling.\n",
    "There are several ways to implement this, but if you need help, you can use the following steps between the creation of embeddings and the mask/pool operations to process bigrams:\n",
    "1. create two slices of the embedding tensor, one with the first character cut off and one with the last cut off\n",
    "2. concatenate the two sliced tensors along the embedding dimension with `torch.cat`\n",
    "3. run a linear layer with activation on the concatenated embeddings\n",
    "4. cut off the first character of the mask tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 132731,
     "status": "ok",
     "timestamp": 1611629044182,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "-hT0Fj_de2j5",
    "outputId": "7b1b3e6b-c7a3-4947-bd6a-214bb08338a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzxf\\AppData\\Local\\Temp\\ipykernel_6592\\2165647061.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm.tqdm_notebook(data_loader, leave=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 76.4\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 79.60000000000001\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.0\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 80.7\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.69999999999999\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.0\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 80.9\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.69999999999999\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.6\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 83.0\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 83.39999999999999\n",
      "Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 83.39999999999999\n",
      "Epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 80.80000000000001\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.19999999999999\n",
      "Epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.8\n",
      "Epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.10000000000001\n",
      "Epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.89999999999999\n",
      "Epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.69999999999999\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.69999999999999\n",
      "Epoch 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 79.9\n",
      "Epoch 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 79.60000000000001\n",
      "Epoch 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 80.80000000000001\n",
      "Epoch 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 82.3\n",
      "Epoch 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd10d25747b4448ea92af60d3e60aeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 81.0\n"
     ]
    }
   ],
   "source": [
    "class ImprovedNetwork(nn.Module):\n",
    "    def __init__(self, n_outputs): # pass whatever arguments you need\n",
    "        super().__init__()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # create Modules from torch.nn (imported as nn)\n",
    "        self.char_embedding = torch.nn.Embedding(128, 128)\n",
    "        self.lstm_net = torch.nn.LSTM(128, 128, num_layers=1, batch_first=True)\n",
    "        self.all_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(128, n_outputs)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, chars, mask):\n",
    "        # for this network, `chars` should be an int64 tensor of character ids with size (batch, n_chars)\n",
    "        # `mask` is a float32 tensor of size (batch, n_chars) that is 1.0 if the character at that position in `chars` is valid (else 0.0)\n",
    "        # the function returns a float32 tensor of size (batch, n_pos)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        embeddings = self.char_embedding(chars) * torch.unsqueeze(mask, -1)\n",
    "        output, _ = self.lstm_net(embeddings)\n",
    "        word_length = torch.sum(mask > 0, dim=1)\n",
    "        output = output[torch.arange(chars.shape[0]), word_length, :]\n",
    "        return self.all_net(output)\n",
    "\n",
    "trained_improved_network = train(ImprovedNetwork(len(all_tags)))\n",
    "improved_predictor = predict_using(trained_improved_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaTxzvNgxtDR"
   },
   "source": [
    "We can also get a feel for what our model learned by providing some of our own inputs that aren't real words (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 132727,
     "status": "ok",
     "timestamp": 1611629044183,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "AFMX_RBKT1oN",
    "outputId": "48eeafaf-5d46-4909-aa89-9500cf42507e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: [('salem', 'NOUN'), ('unsympathetic', 'ADJ'), ('downwind', 'NOUN'), ('exodus', 'ADJ'), ('avoiding', 'VERB'), ('informal', 'ADJ'), ('padded', 'VERB'), ('tantalizing', 'VERB'), ('farce', 'NOUN'), ('berger', 'NOUN')]\n",
      "Sample predictions: [('kleining', 'VERB'), ('deneroful', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "print_sample_predictions(improved_predictor, validation_data_raw)\n",
    "\n",
    "print_sample_predictions(improved_predictor, [['kleining','X'], ['deneroful','X']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrsWMTREe9EY"
   },
   "source": [
    "Finally, you need to run your model on the test set and save the outputs.  You'll turn in your predictions for us to grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 133127,
     "status": "ok",
     "timestamp": 1611629044588,
     "user": {
      "displayName": "Rudy Corona Rodriguez",
      "photoUrl": "",
      "userId": "02448394073714905143"
     },
     "user_tz": 480
    },
    "id": "uRxZb1LBfVmf",
    "outputId": "39fea334-2cd3-455d-ae68-b660fe21212a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score pooling: 68.8\n",
      "test score improved: 84.39999999999999\n"
     ]
    }
   ],
   "source": [
    "def save_predictions(predictions, filename):\n",
    "    \"\"\"Save predictions to a file.\n",
    "    \n",
    "    predictions is a list of strings.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for pred in predictions:\n",
    "            f.write(pred)\n",
    "            f.write('\\n')\n",
    "\n",
    "print('test score pooling:', evaluate(pooling_predictor, test_data_raw))\n",
    "print('test score improved:', evaluate(improved_predictor, test_data_raw))\n",
    "\n",
    "test_predictions = pooling_predictor(test_data_raw)\n",
    "save_predictions(test_predictions, 'predicted_test_outputs_pooling.txt')\n",
    "test_predictions = improved_predictor(test_data_raw)\n",
    "save_predictions(test_predictions, 'predicted_test_outputs_improved.txt')\n",
    "\n",
    "# Check that your test set looks like we expect it to\n",
    "import hashlib\n",
    "m = hashlib.md5()\n",
    "m.update(str(test_data_raw).encode('utf-8'))\n",
    "assert m.digest() == b'*N\\xf6\\xbe\\xed\\xde\\xe8q)\\xb9GG\\xa6\\x15UI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "You will submit this notebook and the required output files that we specify.  For this project, your submission will contain:\n",
    "* hw1a.ipynb\n",
    "* predicted_test_outputs_pooling.txt\n",
    "* predicted_test_outputs_improved.txt\n",
    "\n",
    "You can upload files individually or as part of a zip file, but if using a zip file be sure you are zipping the files directly and not a folder that contains them.\n",
    " \n",
    "To download this notebook, go to `File->Download .ipynb`.  Please rename the file to match the name in our file list.  You can download other outputs, like `predicted_test_output_improved.txt` by clicking the > arrow near the top left and finding it under `Files`.\n",
    "\n",
    "When submitting your ipython notebooks, make sure everything runs correctly if the cells are executed in order starting from a fresh session.  Note that just because a cell runs in your current session doesn't mean it doesn't rely on code that you have already changed or deleted.  If the code doesn't take too long to run, we recommend re-running everything with `Runtime->Restart and run all...`.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py001",
   "language": "python",
   "name": "py001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
